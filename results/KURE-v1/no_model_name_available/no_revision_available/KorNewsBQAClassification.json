{
  "dataset_revision": "main",
  "evaluation_time": 39.29495716094971,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.49",
  "scores": {
    "train": [
      {
        "accuracy": 0.5253206106870231,
        "ap": 0.6914623536715329,
        "ap_weighted": 0.6914623536715329,
        "f1": 0.4987432562208206,
        "f1_weighted": 0.5362067933943226,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "main_score": 0.5253206106870231,
        "scores_per_experiment": [
          {
            "accuracy": 0.5658015267175572,
            "ap": 0.708925553699385,
            "ap_weighted": 0.708925553699385,
            "f1": 0.541904921257577,
            "f1_weighted": 0.5801458794602459
          },
          {
            "accuracy": 0.5278625954198474,
            "ap": 0.6749679704716856,
            "ap_weighted": 0.6749679704716856,
            "f1": 0.48035370004218625,
            "f1_weighted": 0.537781771506019
          },
          {
            "accuracy": 0.526793893129771,
            "ap": 0.6895859533672359,
            "ap_weighted": 0.6895859533672359,
            "f1": 0.5028834929354942,
            "f1_weighted": 0.5427313857757996
          },
          {
            "accuracy": 0.47961832061068704,
            "ap": 0.6814490745062303,
            "ap_weighted": 0.6814490745062303,
            "f1": 0.47008582825018297,
            "f1_weighted": 0.49606281938398683
          },
          {
            "accuracy": 0.4545801526717557,
            "ap": 0.6927186756667608,
            "ap_weighted": 0.6927186756667608,
            "f1": 0.45455929936229306,
            "f1_weighted": 0.45579196165497365
          },
          {
            "accuracy": 0.5154198473282443,
            "ap": 0.682785389225657,
            "ap_weighted": 0.682785389225657,
            "f1": 0.4896444191627809,
            "f1_weighted": 0.5315645108938403
          },
          {
            "accuracy": 0.510381679389313,
            "ap": 0.6971772382575312,
            "ap_weighted": 0.6971772382575312,
            "f1": 0.5012140393555049,
            "f1_weighted": 0.5259295013385415
          },
          {
            "accuracy": 0.5759541984732824,
            "ap": 0.6896761093947703,
            "ap_weighted": 0.6896761093947703,
            "f1": 0.515512130419004,
            "f1_weighted": 0.5780573264086053
          },
          {
            "accuracy": 0.5237404580152671,
            "ap": 0.708090851584774,
            "ap_weighted": 0.708090851584774,
            "f1": 0.5168805588972476,
            "f1_weighted": 0.5379216844431014
          },
          {
            "accuracy": 0.5730534351145038,
            "ap": 0.6892467205412989,
            "ap_weighted": 0.6892467205412989,
            "f1": 0.5143941725259349,
            "f1_weighted": 0.5760810930781133
          }
        ]
      }
    ]
  },
  "task_name": "KorNewsBQAClassification"
}