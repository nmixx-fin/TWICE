{
  "dataset_revision": "main",
  "evaluation_time": 269.1313388347626,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.49",
  "scores": {
    "train": [
      {
        "accuracy": 0.5247480916030532,
        "ap": 0.6896192032889659,
        "ap_weighted": 0.6896192032889659,
        "f1": 0.4988758559265884,
        "f1_weighted": 0.5380297213247605,
        "hf_subset": "default",
        "languages": [
          "kor-Hang"
        ],
        "main_score": 0.5247480916030532,
        "scores_per_experiment": [
          {
            "accuracy": 0.5293129770992366,
            "ap": 0.7010209820160694,
            "ap_weighted": 0.7010209820160694,
            "f1": 0.5156526953288961,
            "f1_weighted": 0.5453824358363464
          },
          {
            "accuracy": 0.5237404580152671,
            "ap": 0.6872075373602282,
            "ap_weighted": 0.6872075373602282,
            "f1": 0.49867865280728674,
            "f1_weighted": 0.539646875182094
          },
          {
            "accuracy": 0.5332824427480916,
            "ap": 0.695100201427098,
            "ap_weighted": 0.695100201427098,
            "f1": 0.5120929889721493,
            "f1_weighted": 0.5492560309791866
          },
          {
            "accuracy": 0.48801526717557253,
            "ap": 0.6807991251706109,
            "ap_weighted": 0.6807991251706109,
            "f1": 0.47444527638717726,
            "f1_weighted": 0.5053113646982634
          },
          {
            "accuracy": 0.477175572519084,
            "ap": 0.6815937320066886,
            "ap_weighted": 0.6815937320066886,
            "f1": 0.46865384341713157,
            "f1_weighted": 0.49324820082529797
          },
          {
            "accuracy": 0.5519083969465649,
            "ap": 0.6795140512879513,
            "ap_weighted": 0.6795140512879513,
            "f1": 0.4923213278994323,
            "f1_weighted": 0.555891489797309
          },
          {
            "accuracy": 0.5009923664122138,
            "ap": 0.6932501950741676,
            "ap_weighted": 0.6932501950741676,
            "f1": 0.4924346477610066,
            "f1_weighted": 0.5165230410014414
          },
          {
            "accuracy": 0.5627480916030534,
            "ap": 0.6899654213394171,
            "ap_weighted": 0.6899654213394171,
            "f1": 0.514387919796347,
            "f1_weighted": 0.5703986848206601
          },
          {
            "accuracy": 0.5299236641221374,
            "ap": 0.7031466680552023,
            "ap_weighted": 0.7031466680552023,
            "f1": 0.5176941689648444,
            "f1_weighted": 0.5457645538225236
          },
          {
            "accuracy": 0.5503816793893129,
            "ap": 0.6845941191522258,
            "ap_weighted": 0.6845941191522258,
            "f1": 0.5023970379316123,
            "f1_weighted": 0.5588745362844812
          }
        ]
      }
    ]
  },
  "task_name": "KorNewsBQAClassification"
}